{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #linear algebra\n",
    "import pandas as pd #data processing \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IMDB_Title_Akas = pd.read_csv(\"./Prj_Data/DownLoadedData_Imdb/imdb_title_akas.tsv\", delimiter='\\t')\n",
    "df_IMDB_Title_Akas.name = \"df_IMDB_Title_Akas\"\n",
    "\n",
    "df_IMDB_Title_Akas = df_IMDB_Title_Akas.loc[(df_IMDB_Title_Akas['titleType']=='movie')]\n",
    "df_IMDB_Title_Akas = df_IMDB_Title_Akas.loc[(df_IMDB_Title_Akas['isAdult']==0)]\n",
    "df_IMDB_Title_Akas = df_IMDB_Title_Akas.loc[~(df_IMDB_Title_Akas['genres']=='\\\\N')]\n",
    "df_IMDB_Title_Akas.drop(['endYear', 'isAdult'], axis=1, inplace = True)\n",
    "\n",
    "df_IMDB_Title_Akas[\"startYear\"] = df_IMDB_Title_Akas.startYear.replace(r'\\N',\"0\", regex=False)\n",
    "df_IMDB_Title_Akas['startYear'] = df_IMDB_Title_Akas['startYear'].astype('int32')\n",
    "\n",
    "\n",
    "df_IMDB_Title_Akas[\"runtimeMinutes\"] = df_IMDB_Title_Akas.runtimeMinutes.replace(r'\\N',\"0\", regex=False)\n",
    "df_IMDB_Title_Akas['runtimeMinutes'] = df_IMDB_Title_Akas['runtimeMinutes'].astype('float64')\n",
    "\n",
    "# df_IMDB_Title_Akas = df_IMDB_Title_Akas[df_IMDB_Title_Akas.primaryTitle.str.isalpha()]\n",
    "df_IMDB_Title_Akas.dropna(subset=['primaryTitle'], how='all', inplace=True)\n",
    "df_IMDB_Title_Akas.fillna({\"startYear\":0,\"runtimeMinutes\":0}, inplace=True)\n",
    "df_IMDB_Title_Akas = df_IMDB_Title_Akas.loc[(df_IMDB_Title_Akas['startYear']>=2005) & (df_IMDB_Title_Akas['startYear']<=2020)]\n",
    "\n",
    "\n",
    "df_IMDB_Title_Akas = df_IMDB_Title_Akas[df_IMDB_Title_Akas['primaryTitle'].str.contains('[A-Za-z0-9:-]', na=False, regex=True)]\n",
    "df_IMDB_Title_Akas = df_IMDB_Title_Akas.loc[~(df_IMDB_Title_Akas['primaryTitle'].str.contains('á|à|â|ã|é|è|ê|í|ï|ó|ô|õ|ö|ú|ç|ñ', case=False))]\n",
    "\n",
    "\n",
    "df_IMDB_Title_Ratings = pd.read_csv(\"./Prj_Data/DownLoadedData_Imdb/Ratings.tsv\", delimiter='\\t')\n",
    "df_Imdb_MoviesWithRatings = df_IMDB_Title_Akas.merge(df_IMDB_Title_Ratings, on='tconst', how='inner', suffixes=('_AK', '_rat'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____________________________________________Indexes To Feed Into Scraping Funcation\n",
    "\n",
    "#df_ttTolookup = pd.read_excel(\"df_ttTolookup.xlsx\")\n",
    "\n",
    "#df_0_7776 = df_ttTolookup.iloc[0:7776,]\n",
    "        #df_0_7776.index = df_ttTolookup.iloc[0:7776,].index last row to complete 11235\n",
    "#df_11236_14000 = df_ttTolookup.iloc[11236:14000,]\n",
    "#df_11236_14000[\"index_O\"] = df_ttTolookup.iloc[11236:14000,].index \n",
    "# df_14000_19999 = df_ttTolookup.iloc[14000:20000,]\n",
    "# df_14000_19999[\"index_O\"] = df_ttTolookup.iloc[14000:20000,].index\n",
    "\n",
    "#df_20000_24999v1 = df_ttTolookup_Backup.iloc[20000:25000,]\n",
    "# df_20000_24999v1[\"index_O\"] = df_ttTolookup_Backup.iloc[20000:25000,].index\n",
    "\n",
    "\n",
    "# df_20000_21910 = df_ttTolookup.iloc[20000:21910,]\n",
    "# df_21910_24999[\"index_O\"] = df_ttTolookup.iloc[20000:21910,].index\n",
    "\n",
    "# df_21909_24999 = df_ttTolookup.iloc[21910:25000,]\n",
    "# df_21909_24999[\"index_O\"] = df_ttTolookup.iloc[21910:25000,].index\n",
    "\n",
    "# df_25000_29999 = df_ttTolookup.iloc[21910:30000,]\n",
    "# df_25000_29999[\"index_O\"] = df_ttTolookup.iloc[21910:30000,].index\n",
    "\n",
    "# df_29290_36177 = df_ttTolookup.iloc[29290:36177,]\n",
    "# df_29290_36177[\"index_O\"] = df_ttTolookup.iloc[29290:36177,].index\n",
    "\n",
    "\n",
    "# df_36177_39999 = df_ttTolookup.iloc[36177:40000,]\n",
    "# df_36177_39999[\"index_O\"] = df_ttTolookup.iloc[36177:40000,].index\n",
    "\n",
    "# df_40000_40629 = df_ttTolookup.iloc[40000:40629,]\n",
    "# df_40000_40629[\"index_O\"] = df_ttTolookup.iloc[40000:40629,].index\n",
    "\n",
    "# df_40628_45000 = df_ttTolookup.iloc[40629:45000,]\n",
    "# df_40628_45000[\"index_O\"] = df_ttTolookup.iloc[40629:45000,].index\n",
    "\n",
    "# df_45000_47252 = df_ttTolookup.iloc[45000:47252,]\n",
    "# df_45000_47252[\"index_O\"] = df_ttTolookup.iloc[45000:47252,].index\n",
    "\n",
    "# df_47252_47778 = df_ttTolookup.iloc[47252:47778,]\n",
    "# df_47252_47778[\"index_O\"] = df_ttTolookup.iloc[47252:47778,].index\n",
    "\n",
    "# df_47778_48108 = df_ttTolookup.iloc[47778:48108,]\n",
    "# df_47778_48108[\"index_O\"] = df_ttTolookup.iloc[47778:48108,].index\n",
    "\n",
    "# df_48108_49999 = df_ttTolookup.iloc[48108:50000,]\n",
    "# df_48108_49999[\"index_O\"] = df_ttTolookup.iloc[48108:50000,].index\n",
    "\n",
    "# df_50000_51418 = df_ttTolookup.iloc[50000:51418,]\n",
    "# df_50000_51418[\"index_O\"] = df_ttTolookup.iloc[50000:51418,].index\n",
    "\n",
    "\n",
    "# df_51418_52224 = df_ttTolookup.iloc[51418:52224,]\n",
    "# df_51418_52224[\"index_O\"] = df_ttTolookup.iloc[51418:52224,].index\n",
    "\n",
    "\n",
    "# df_52224_52561 = df_ttTolookup.iloc[52224:52561,]\n",
    "# df_52224_52561[\"index_O\"] = df_ttTolookup.iloc[52224:52561,].index\n",
    "\n",
    "# df_52561_55000 = df_ttTolookup.iloc[52561:55000,]\n",
    "# df_52561_55000[\"index_O\"] = df_ttTolookup.iloc[52561:55000,].index\n",
    "\n",
    "# df_55000_60000 = df_ttTolookup.iloc[55000:60000,]\n",
    "# df_55000_60000[\"index_O\"] = df_ttTolookup.iloc[55000:60000,].index\n",
    "\n",
    "\n",
    "# df_60000_63054 = df_ttTolookup.iloc[60000:,]\n",
    "# df_60000_63054[\"index_O\"] = df_ttTolookup.iloc[60000:,].index\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 get top line\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq # get url\n",
    "import re\n",
    "\n",
    "df_Summary_financials = pd.DataFrame(columns = [\"tconst\", \"Index_O\", \"Domestic\", \"International\", \"Worldwide\"])\n",
    "df_Summary_details = pd.DataFrame(columns = [\"tconst\", \"Domestic Distributor\", \"Domestic Opening\", \"Budget\", \n",
    "                                             \"Earliest Release Date\", \"MPAA\", \"Running Time\", \"Genre\",\"IMDbPro\"])\n",
    "#if True:\n",
    "#df_ttTolookup\n",
    "\n",
    "for index, row in df_60000_63054.iterrows():\n",
    "    #print(index)\n",
    "    #print (row)\n",
    "    \n",
    "#for index, row in df_IMDB_Title_Akas.iterrows():\n",
    "    #print(row[\"tconst\"])\n",
    "    #print(row[\"index_O\"])\n",
    "    #break\n",
    "#     #current_ttconst = 'tt2527338'\n",
    "    \n",
    "    current_ttconst = row[\"tconst\"]\n",
    "    ddToLookupIndex = row[\"index_O\"]\n",
    "    \n",
    "    summaryheaders = []\n",
    "    summaryfinancials = []\n",
    "    summarydata = {}\n",
    "    \n",
    "    detailheaders = []\n",
    "    detaildata = []\n",
    "    detailsummary = {}\n",
    "    \n",
    "    the_getString = 'https://www.boxofficemojo.com/title/'+current_ttconst\n",
    "    r=rq.get(the_getString)\n",
    "    p=bs(r.text,'html.parser')\n",
    "    \n",
    "    summaryheaders.append(\"tconst\")\n",
    "    summaryheaders.append(\"index\")\n",
    "    \n",
    "    summaryfinancials.append(current_ttconst)\n",
    "    summaryfinancials.append(ddToLookupIndex)\n",
    "    \n",
    "    # get Summary data\n",
    "    b=p.find('div', class_=\"a-section a-spacing-none mojo-performance-summary-table\")\n",
    "    if b:\n",
    "        b=p.find('div', class_=\"a-section a-spacing-none mojo-performance-summary-table\")\n",
    "        divs=b.find_all('div', class_=\"a-section a-spacing-none\")\n",
    "        if divs:\n",
    "        #append keys\n",
    "            for div in divs:\n",
    "                spans = div.find_all('span', class_=[\"a-size-small\",\"money\"])\n",
    "                if spans:\n",
    "                    for span in spans:\n",
    "                        #print(span.text.strip())\n",
    "\n",
    "                        #remove () and from values so you can have consistent key accross dictionaries\n",
    "                        thedata = re.sub(r'\\([^)]*\\)', '', span.text.strip()).strip()\n",
    "\n",
    "                        # must be a # remove $ signes so we can sum later\n",
    "                        if re.sub('[^0-9]',\"\", thedata):\n",
    "                            finanicals=re.sub('[^0-9-]',\"\", thedata)\n",
    "                            finanicals = int(finanicals)\n",
    "                            summaryfinancials.append(finanicals)\n",
    "                        else :\n",
    "                            #if no # in detected above must be a header so i add :\n",
    "                            summaryheaders.append(thedata)\n",
    "\n",
    "    summarydata = dict(zip(summaryheaders, summaryfinancials))\n",
    "    df_Summary_financials = df_Summary_financials.append(summarydata, ignore_index=True)\n",
    "                #print(type(summarydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttTolookup = pd.read_excel(\"df_ttTolookup_DomensticWithSales.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__________________________________________________________\n",
    "\n",
    "# step 2 get detailed data\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq # get url\n",
    "import re\n",
    "\n",
    "df_Summary_financials = pd.DataFrame(columns = [\"tconst\", \"Domestic\", \"International\", \"Worldwide\"])\n",
    "df_Summary_details = pd.DataFrame(columns = [\"tconst\", \"Index_O\" \"Domestic Distributor\", \"Domestic Opening\", \"Budget\", \n",
    "                                             \"Earliest Release Date\", \"MPAA\", \"Running Time\", \"Genre\",\"IMDbPro\"])\n",
    "#if True:\n",
    "#df_ttTolookup\n",
    "\n",
    "for index, row in df_ttTolookup.iterrows():\n",
    "    #print(index)\n",
    "    #print (row)\n",
    "    \n",
    "#for index, row in df_IMDB_Title_Akas.iterrows():\n",
    "    #print(row[\"tconst\"])\n",
    "    #print(row[\"index_O\"])\n",
    "    #break\n",
    "#     #current_ttconst = 'tt2527338'\n",
    "    \n",
    "    current_ttconst = row[\"tconst\"]\n",
    "#     ddToLookupIndex = row[\"Index_O\"]\n",
    "        \n",
    "    detailheaders = []\n",
    "    detaildata = []\n",
    "    detailsummary = {}\n",
    "    \n",
    "    the_getString = 'https://www.boxofficemojo.com/title/'+current_ttconst\n",
    "    r=rq.get(the_getString)\n",
    "    p=bs(r.text,'html.parser')\n",
    "    \n",
    "\n",
    "    detailheaders.append(\"tconst\")\n",
    "#     detailheaders.append(\"Index_O)\n",
    "    detaildata.append(current_ttconst)\n",
    "    #detaildata.append(ddToLookupIndex)\n",
    "                     \n",
    "                     \n",
    "    b=p.find('div', class_=\"a-section a-spacing-none mojo-summary-values mojo-hidden-from-mobile\")\n",
    "    if b:\n",
    "        if b.find_all('span'):\n",
    "            spans=b.find_all('span')\n",
    "            #print(len(spans))\n",
    "            iteration = 1\n",
    "            for span in spans:\n",
    "                # get rid of \"a\" tags\n",
    "                if span.a:\n",
    "                    next\n",
    "                # get rid of sub span tags\n",
    "                if span.span:\n",
    "                    next\n",
    "                else:\n",
    "                    if (iteration % 2) == 0:\n",
    "                        iteration +=1\n",
    "                        # this is even - meaning a detail row\n",
    "                        detaildata.append(span.text.strip())              \n",
    "                    else:\n",
    "                       # this is odd - meaning a headerrow\n",
    "                        #print(span.text)\n",
    "                        iteration +=1\n",
    "                        detailheaders.append(span.text.strip())\n",
    "                        #data=[item for item in data]\n",
    "                        #data=[re.sub('[^0-9]',\"\", str(item)) for item in data]\n",
    "\n",
    "    detailsummary = dict(zip(detailheaders, detaildata))\n",
    "    #alldata.append(ttconst)\n",
    "    #alldata.append(summarydata)\n",
    "    df_Summary_details = df_Summary_details.append(detailsummary, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Summary_details.to_excel(\"df_Summary_details.xlsx\", header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
